{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp do Uczenia Maszynowego - Lab 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie dzisiejsze metody można znaleźć dokładnie (i przystępnie!) omówione na StatQuest: https://www.youtube.com/user/joshstarmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:16.256846Z",
     "start_time": "2020-03-23T09:42:15.442652Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "np.random.seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:16.281787Z",
     "start_time": "2020-03-23T09:42:16.261833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>Absent</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>Present</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>Present</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>Present</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11  Present     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61   Absent     55    28.87     2.06   63    1\n",
       "2  118     0.08  3.48      32.28  Present     52    29.14     3.81   46    0\n",
       "3  170     7.50  6.41      38.03  Present     51    31.99    24.26   58    1\n",
       "4  134    13.60  3.50      27.78  Present     60    25.99    57.34   49    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:16.288795Z",
     "start_time": "2020-03-23T09:42:16.283777Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array(data['chd'])\n",
    "X = data.drop(['chd'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:16.304107Z",
     "start_time": "2020-03-23T09:42:16.291084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age\n",
       "0  160    12.00  5.73      23.11        1     49    25.30    97.20   52\n",
       "1  144     0.01  4.41      28.61        0     55    28.87     2.06   63\n",
       "2  118     0.08  3.48      32.28        1     52    29.14     3.81   46\n",
       "3  170     7.50  6.41      38.03        1     51    31.99    24.26   58\n",
       "4  134    13.60  3.50      27.78        1     60    25.99    57.34   49"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict = {'Present': 1, 'Absent':0}\n",
    "X['famhist'] = X['famhist'].map(map_dict)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods - Komitety\n",
    "Często kilka osób, które myślą nad daną sprawą, potrafi dać lepszą odpowiedź niż jedna osoba. Nawet jeśli żadna z osób nie jest ekspertem.  \n",
    "To podejście zadziała, gdy błędny popełniane przez różne modele są od siebie niezależne (w miarę). \n",
    "\n",
    "  \n",
    "Na potrzeby stosowania różnych metod Ensemble Learningu załadujemy sobie już 3 modele z których będziemy potem korzystać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:04:23.248656Z",
     "start_time": "2020-03-23T10:04:23.241676Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = DecisionTreeClassifier(random_state=1)\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression(random_state=1, max_iter=1000)\n",
    "estimators=[('DecisionTree', model1), ('KNN', model2), ('LR', model3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voting\n",
    "lub Hard Voting - głosowanie większościowe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:04:23.752520Z",
     "start_time": "2020-03-23T10:04:23.748530Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:04:24.077640Z",
     "start_time": "2020-03-23T10:04:24.044296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6881720430107527\n",
      "model.score:  0.6881720430107527\n"
     ]
    }
   ],
   "source": [
    "model_hard = VotingClassifier(estimators=estimators, voting='hard')\n",
    "model_hard.fit(X_train,y_train)\n",
    "\n",
    "y_hat = model_hard.predict(X_test)\n",
    "print('accuracy: ', accuracy_score(y_test, y_hat))\n",
    "\n",
    "# model też ma inną metodę ewaluacji i jest to też accuracy w przypadku klasyfikacji\n",
    "print('model.score: ', model_hard.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging\n",
    "Soft Voting. Nie patrzymy na liczbę głosów, ale na \"pewność\". Patrzymy na ile pewny jest klasyfikator, że rekord należy do klasy 1. c1 - 90%, c2 - 49%, c3 - 49% \n",
    "* hard voting: klasa 0 (1 głos na tak, 2 głosy na nie)\n",
    "* soft voting: klasa 1 ( (90 + 49 + 49)/3 $\\approx$ 63% > 50%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6236559139784946"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_soft = VotingClassifier(estimators=estimators, voting='soft')\n",
    "model_soft.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model_soft.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights\n",
    "Nie musimy zawsze uważać, że każdy klasyfikator ma tyle samo do powiedzenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7419354838709677"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_soft = VotingClassifier(estimators=estimators, voting='soft', weights=[0.05, 0.05, 0.90])\n",
    "model_soft.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model_soft.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "<div>\n",
    "<img src=\"https://miro.medium.com/max/700/1*RP0pkQEOSrw9_EjFu4w3gg.png\" />\n",
    "</div>\n",
    "source: https://miro.medium.com/max/700/1*RP0pkQEOSrw9_EjFu4w3gg.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bierzemy kilka różnych modeli (base) i jeden meta-model. Meta-model uczy się przewidzieć wynik na podstawie wyników z base.\n",
    "\n",
    "Zasada kciuka: ostatni model jest raczej prosty (regresja liniowa/logistyczna).  \n",
    "Więcej (np. o trenowaniu) tutaj: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n",
    "\n",
    "\n",
    "Czy można stackować kilka takich samych modeli?  \n",
    "Tak, omówimy to za chwilę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:05:20.908643Z",
     "start_time": "2020-03-23T10:05:20.904653Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:05:21.255832Z",
     "start_time": "2020-03-23T10:05:21.177931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7741935483870968"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging (Bootstrap Aggregating)\n",
    "Bootstrap - to technika próbkowania, w której tworzymy podzbiory (próby) obserwacji z oryginalnego datasetu, **ze zwracaniem**. Rozmiar podzbiorów jest taki sam jak rozmiar oryginalnego datasetu.\n",
    "\n",
    "1. Losujemy N **bootstrapowych** prób ze zbioru treningowego\n",
    "2. Trenujemy niezależnie N \"słabych\" klasyfikatorów\n",
    "3. Składamy wyniki \"słabych\" modeli \n",
    "    - **Klasyfikacja:** reguła większościowa / uśrednione prawdopodobieństwo\n",
    "    - **Regresja:** Uśrednione wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:09:09.734084Z",
     "start_time": "2020-03-23T10:09:09.729082Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:40:53.981479Z",
     "start_time": "2020-03-23T10:40:53.956920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6559139784946236"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_estimator=model1,\n",
    "                        n_estimators=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Najbardziej popularny algorytm Baggingowy. Wiele małych drzew.\n",
    "\n",
    "Przypomnijmy\n",
    "#### Zalety drzew\n",
    "* interpretowalność\n",
    "* prostota + wizualizacja\n",
    "* nie trzeba normalizować danych \\:)\n",
    "* odporne na wartości skrajne\n",
    "* z ich użyciem można wykrywać ważne cechy\n",
    "\n",
    "#### Wady drzew\n",
    "* łatwo o overfitting\n",
    "* drzewo długo rośnie\n",
    "* starych drzew się nie przesadza - nie da się dotrenować algorytmu po jakimś czasie, trzeba zasadzić nowe \n",
    "* jest duża losowość - na tych samych danych algorytm może dawać bardzo różne wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:40:19.674175Z",
     "start_time": "2020-03-23T10:40:19.670184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7204301075268817"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=1000, # Ilość słabych estymatorów\n",
    "                                  max_depth=2, # Maksymalna wysokość drzewa w słabym estymatorze\n",
    "                                  min_samples_split = 2, # Minimalna ilość obserwacji wymagana do podziału węzła\n",
    "                                  max_features = 3, # Maksymalna ilość zmiennych brana pod uwagę przy podziale węzła\n",
    "                                  random_state=0,\n",
    "                                  n_jobs = -1)\n",
    "model_rf.fit(X_train, y_train)\n",
    "model_rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "Boosting działa podobnie jak Bagging z jedną różnicą. Każda kolejna próba bootstrap jest tworzona w taki sposób,  \n",
    "że losuje z większym prawdopodobieństwiem obserwacje **źle sklasyfikowane**.  \n",
    "W skrócie: Boosting uczy się na błędach, które popełnił w poprzednich iteracjach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost\n",
    "Najprostsza metoda boostingowa.  \n",
    "Większe prawdopodobieństwo wylosowania próbek, na których podczas predykcji został popełniony błąd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:50:26.312390Z",
     "start_time": "2020-03-23T10:50:26.308376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7204301075268817"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting\n",
    "Zaczynamy od pojedynczej predykcji (np. średniej) i liczymy różnicę, tzw. residuum.  \n",
    "Następnie każdy model próbuje przewidzieć residuum.  \n",
    "W GB każdy model ma taki sam głos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:50:44.448951Z",
     "start_time": "2020-03-23T10:50:44.444975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7204301075268817"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=1,\n",
    "                                  learning_rate=0.01)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "Zaawansowana implementacja Gradient Boostingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:51:55.997278Z",
     "start_time": "2020-03-23T10:51:55.993198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /hdd/anaconda3/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/jan/.local/lib/python3.8/site-packages (from xgboost) (1.22.3)\n",
      "Requirement already satisfied: scipy in /home/jan/.local/lib/python3.8/site-packages (from xgboost) (1.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier # Inna paczka niż sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T12:45:09.842895Z",
     "start_time": "2020-03-23T12:45:09.783537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:41:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"nround\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:41:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/hdd/anaconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7526881720430108"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=XGBClassifier(random_state=1,\n",
    "                    learning_rate=0.01, # Szybkość \"uczenia\" się\n",
    "                    booster='gbtree', # Jaki model wykorzystujemy (drzewo - gbtree, liniowe - gblinear)\n",
    "                    nround = 100, # Ilość itereacji boosingowych\n",
    "                    max_depth=4 # Maksymalna głębokość drzewa \n",
    "                    )\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przygotowanie stacking\n",
    "def get_stacking():\n",
    "    \n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression()))\n",
    "    level0.append(('cart', DecisionTreeClassifier(random_state=1)))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('rf', RandomForestClassifier(n_estimators=1000, # Ilość słabych estymatorów\n",
    "                                      max_depth=2, # Maksymalna wysokość drzewa w słabym estymatorze\n",
    "                                      min_samples_split = 2, # Minimalna ilość obserwacji wymagana do podziału węzła\n",
    "                                      max_features = 3, # Maksymalna ilość zmiennych brana pod uwagę przy podziale węzła\n",
    "                                      random_state=0,\n",
    "                                      n_jobs = -1)))\n",
    "    level0.append(('aboost', AdaBoostClassifier(random_state=1)))\n",
    "    level0.append(('gboost', GradientBoostingClassifier(random_state=1,\n",
    "                                      learning_rate=0.01)))\n",
    "    level0.append(('xgb', XGBClassifier(random_state=1,\n",
    "                        learning_rate=0.01, # Szybkość \"uczenia\" się\n",
    "                        booster='gbtree', # Jaki model wykorzystujemy (drzewo - gbtree, liniowe - gblinear)\n",
    "                        max_depth=4 # Maksymalna głębokość drzewa \n",
    "                        )))\n",
    "    level0.append(('svm', SVC()))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    \n",
    "    # definicja meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    \n",
    "    # definicja stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista modeli\n",
    "def get_models():\n",
    "    \n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=1000, # Ilość słabych estymatorów\n",
    "                                      max_depth=2, # Maksymalna wysokość drzewa w słabym estymatorze\n",
    "                                      min_samples_split = 2, # Minimalna ilość obserwacji wymagana do podziału węzła\n",
    "                                      max_features = 3, # Maksymalna ilość zmiennych brana pod uwagę przy podziale węzła\n",
    "                                      random_state=0,\n",
    "                                      n_jobs = -1)\n",
    "    models['aboost'] = AdaBoostClassifier(random_state=1)\n",
    "    models['gboost'] = GradientBoostingClassifier(random_state=1,\n",
    "                                      learning_rate=0.01)\n",
    "    models['xgb'] = XGBClassifier(random_state=1,\n",
    "                        learning_rate=0.01, # Szybkość \"uczenia\" się\n",
    "                        booster='gbtree', # Jaki model wykorzystujemy (drzewo - gbtree, liniowe - gblinear)\n",
    "                        max_depth=4 # Maksymalna głębokość drzewa \n",
    "                        )\n",
    "    models['svm'] = SVC()\n",
    "    models['bayes'] = GaussianNB()\n",
    "    models['stacking'] = get_stacking()\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocena modeli przy wykorzystaniu cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lr mean-0.722 std-0.037\n",
      "    cart mean-0.611 std-0.064\n",
      "     knn mean-0.618 std-0.046\n",
      "      rf mean-0.713 std-0.045\n",
      "  aboost mean-0.675 std-0.045\n",
      "  gboost mean-0.723 std-0.050\n"
     ]
    }
   ],
   "source": [
    "# modele do evaluacji\n",
    "models = get_models()\n",
    "# ocena modeli\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('%8s mean-%.3f std-%.3f' % (name, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot acc dla modeli i stacking\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wszystkie dzisiejsze metody można znaleźć dokładnie (i przystępnie!) omówione na StatQuest: https://www.youtube.com/user/joshstarmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
